{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "images_df = pd.read_csv('final_images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Separating X and Y</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>canny_mean</th>\n",
       "      <th>canny_std</th>\n",
       "      <th>canny_var</th>\n",
       "      <th>canny_skew</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>...</th>\n",
       "      <th>r_std</th>\n",
       "      <th>r_var</th>\n",
       "      <th>r_skew</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>energy</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193280</td>\n",
       "      <td>0.394870</td>\n",
       "      <td>0.155923</td>\n",
       "      <td>1.553524</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>13.730138</td>\n",
       "      <td>0.571313</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.093027</td>\n",
       "      <td>-0.504870</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.108318</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.547112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193997</td>\n",
       "      <td>0.395427</td>\n",
       "      <td>0.156362</td>\n",
       "      <td>1.547710</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.112043</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>8.698198</td>\n",
       "      <td>0.419562</td>\n",
       "      <td>0.185652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>-0.203931</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>0.098447</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.456429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234813</td>\n",
       "      <td>0.423882</td>\n",
       "      <td>0.179676</td>\n",
       "      <td>1.251228</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.092706</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>10.599805</td>\n",
       "      <td>0.690965</td>\n",
       "      <td>0.250440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323572</td>\n",
       "      <td>0.104699</td>\n",
       "      <td>-0.628959</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.986431</td>\n",
       "      <td>0.181434</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.338114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.213588</td>\n",
       "      <td>0.409839</td>\n",
       "      <td>0.167968</td>\n",
       "      <td>1.397679</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>0.109054</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>8.949024</td>\n",
       "      <td>0.620038</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293364</td>\n",
       "      <td>0.086063</td>\n",
       "      <td>0.096563</td>\n",
       "      <td>0.049787</td>\n",
       "      <td>0.983035</td>\n",
       "      <td>0.194622</td>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347158</td>\n",
       "      <td>0.476067</td>\n",
       "      <td>0.226639</td>\n",
       "      <td>0.642104</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>5.455466</td>\n",
       "      <td>0.569388</td>\n",
       "      <td>0.316354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324559</td>\n",
       "      <td>0.105338</td>\n",
       "      <td>-0.141203</td>\n",
       "      <td>0.093375</td>\n",
       "      <td>0.972163</td>\n",
       "      <td>0.298515</td>\n",
       "      <td>0.025722</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.230964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.404006</td>\n",
       "      <td>0.163221</td>\n",
       "      <td>-1.458311</td>\n",
       "      <td>0.173589</td>\n",
       "      <td>0.378756</td>\n",
       "      <td>0.143456</td>\n",
       "      <td>1.723597</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.266853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252456</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>0.432834</td>\n",
       "      <td>0.784063</td>\n",
       "      <td>0.777016</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.066447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.560088</td>\n",
       "      <td>0.496376</td>\n",
       "      <td>0.246389</td>\n",
       "      <td>-0.242109</td>\n",
       "      <td>0.113899</td>\n",
       "      <td>0.317689</td>\n",
       "      <td>0.100926</td>\n",
       "      <td>2.430688</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>0.345890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>-0.216155</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.875179</td>\n",
       "      <td>0.619286</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.247640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.598593</td>\n",
       "      <td>0.490183</td>\n",
       "      <td>0.240279</td>\n",
       "      <td>-0.402270</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>0.326514</td>\n",
       "      <td>0.106611</td>\n",
       "      <td>2.319456</td>\n",
       "      <td>0.611764</td>\n",
       "      <td>0.322548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288856</td>\n",
       "      <td>0.083438</td>\n",
       "      <td>-0.284652</td>\n",
       "      <td>0.389769</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.635630</td>\n",
       "      <td>0.076039</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.186485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>0.489756</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.249895</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.181486</td>\n",
       "      <td>0.032937</td>\n",
       "      <td>5.134281</td>\n",
       "      <td>0.668305</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387259</td>\n",
       "      <td>0.149970</td>\n",
       "      <td>-0.483580</td>\n",
       "      <td>0.252763</td>\n",
       "      <td>0.944361</td>\n",
       "      <td>0.459030</td>\n",
       "      <td>0.033215</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.121514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>0.496811</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.249990</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.182557</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>5.099581</td>\n",
       "      <td>0.668425</td>\n",
       "      <td>0.369106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387855</td>\n",
       "      <td>0.150432</td>\n",
       "      <td>-0.485234</td>\n",
       "      <td>0.253146</td>\n",
       "      <td>0.944185</td>\n",
       "      <td>0.459416</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.123661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3833 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std       var      skew  canny_mean  canny_std  \\\n",
       "0     0.193280  0.394870  0.155923  1.553524    0.005222   0.072072   \n",
       "1     0.193997  0.395427  0.156362  1.547710    0.012715   0.112043   \n",
       "2     0.234813  0.423882  0.179676  1.251228    0.008669   0.092706   \n",
       "3     0.213588  0.409839  0.167968  1.397679    0.012038   0.109054   \n",
       "4     0.347158  0.476067  0.226639  0.642104    0.030552   0.172102   \n",
       "...        ...       ...       ...       ...         ...        ...   \n",
       "3828  0.794583  0.404006  0.163221 -1.458311    0.173589   0.378756   \n",
       "3829  0.560088  0.496376  0.246389 -0.242109    0.113899   0.317689   \n",
       "3830  0.598593  0.490183  0.240279 -0.402270    0.121333   0.326514   \n",
       "3831  0.489756  0.499895  0.249895  0.040984    0.034100   0.181486   \n",
       "3832  0.496811  0.499990  0.249990  0.012755    0.034518   0.182557   \n",
       "\n",
       "      canny_var  canny_skew    b_mean     b_std  ...     r_std     r_var  \\\n",
       "0      0.005194   13.730138  0.571313  0.262526  ...  0.305004  0.093027   \n",
       "1      0.012554    8.698198  0.419562  0.185652  ...  0.304782  0.092892   \n",
       "2      0.008594   10.599805  0.690965  0.250440  ...  0.323572  0.104699   \n",
       "3      0.011893    8.949024  0.620038  0.275387  ...  0.293364  0.086063   \n",
       "4      0.029619    5.455466  0.569388  0.316354  ...  0.324559  0.105338   \n",
       "...         ...         ...       ...       ...  ...       ...       ...   \n",
       "3828   0.143456    1.723597  0.656667  0.266853  ...  0.252456  0.063734   \n",
       "3829   0.100926    2.430688  0.578163  0.345890  ...  0.304569  0.092762   \n",
       "3830   0.106611    2.319456  0.611764  0.322548  ...  0.288856  0.083438   \n",
       "3831   0.032937    5.134281  0.668305  0.368840  ...  0.387259  0.149970   \n",
       "3832   0.033327    5.099581  0.668425  0.369106  ...  0.387855  0.150432   \n",
       "\n",
       "        r_skew  contrast  correlation  dissimilarity    energy       ASM  \\\n",
       "0    -0.504870  0.013332     0.996856       0.108318  0.110454  0.012200   \n",
       "1    -0.203931  0.013347     0.994628       0.098447  0.037243  0.001387   \n",
       "2    -0.628959  0.036902     0.986431       0.181434  0.036890  0.001361   \n",
       "3     0.096563  0.049787     0.983035       0.194622  0.102886  0.010586   \n",
       "4    -0.141203  0.093375     0.972163       0.298515  0.025722  0.000662   \n",
       "...        ...       ...          ...            ...       ...       ...   \n",
       "3828 -0.247788  0.432834     0.784063       0.777016  0.011110  0.000123   \n",
       "3829 -0.216155  0.390400     0.875179       0.619286  0.151200  0.022861   \n",
       "3830 -0.284652  0.389769     0.858419       0.635630  0.076039  0.005782   \n",
       "3831 -0.483580  0.252763     0.944361       0.459030  0.033215  0.001103   \n",
       "3832 -0.485234  0.253146     0.944185       0.459416  0.032870  0.001080   \n",
       "\n",
       "      homogeneity  mask  \n",
       "0        0.547112     1  \n",
       "1        0.456429     1  \n",
       "2        0.338114     1  \n",
       "3        0.414035     1  \n",
       "4        0.230964     1  \n",
       "...           ...   ...  \n",
       "3828     0.066447     0  \n",
       "3829     0.247640     0  \n",
       "3830     0.186485     0  \n",
       "3831     0.121514     0  \n",
       "3832     0.123661     0  \n",
       "\n",
       "[3833 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = images_df.drop(columns = ['Unnamed: 0'])\n",
    "images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "3828    0\n",
       "3829    0\n",
       "3830    0\n",
       "3831    0\n",
       "3832    0\n",
       "Name: mask, Length: 3833, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = images_df['mask']\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>canny_mean</th>\n",
       "      <th>canny_std</th>\n",
       "      <th>canny_var</th>\n",
       "      <th>canny_skew</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>...</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>r_var</th>\n",
       "      <th>r_skew</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>energy</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193280</td>\n",
       "      <td>0.394870</td>\n",
       "      <td>0.155923</td>\n",
       "      <td>1.553524</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>13.730138</td>\n",
       "      <td>0.571313</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651805</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.093027</td>\n",
       "      <td>-0.504870</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.108318</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.547112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193997</td>\n",
       "      <td>0.395427</td>\n",
       "      <td>0.156362</td>\n",
       "      <td>1.547710</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.112043</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>8.698198</td>\n",
       "      <td>0.419562</td>\n",
       "      <td>0.185652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464023</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>-0.203931</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>0.098447</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.456429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234813</td>\n",
       "      <td>0.423882</td>\n",
       "      <td>0.179676</td>\n",
       "      <td>1.251228</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.092706</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>10.599805</td>\n",
       "      <td>0.690965</td>\n",
       "      <td>0.250440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656325</td>\n",
       "      <td>0.323572</td>\n",
       "      <td>0.104699</td>\n",
       "      <td>-0.628959</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.986431</td>\n",
       "      <td>0.181434</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.338114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.213588</td>\n",
       "      <td>0.409839</td>\n",
       "      <td>0.167968</td>\n",
       "      <td>1.397679</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>0.109054</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>8.949024</td>\n",
       "      <td>0.620038</td>\n",
       "      <td>0.275387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597236</td>\n",
       "      <td>0.293364</td>\n",
       "      <td>0.086063</td>\n",
       "      <td>0.096563</td>\n",
       "      <td>0.049787</td>\n",
       "      <td>0.983035</td>\n",
       "      <td>0.194622</td>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.414035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347158</td>\n",
       "      <td>0.476067</td>\n",
       "      <td>0.226639</td>\n",
       "      <td>0.642104</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>5.455466</td>\n",
       "      <td>0.569388</td>\n",
       "      <td>0.316354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557730</td>\n",
       "      <td>0.324559</td>\n",
       "      <td>0.105338</td>\n",
       "      <td>-0.141203</td>\n",
       "      <td>0.093375</td>\n",
       "      <td>0.972163</td>\n",
       "      <td>0.298515</td>\n",
       "      <td>0.025722</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.230964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.404006</td>\n",
       "      <td>0.163221</td>\n",
       "      <td>-1.458311</td>\n",
       "      <td>0.173589</td>\n",
       "      <td>0.378756</td>\n",
       "      <td>0.143456</td>\n",
       "      <td>1.723597</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.266853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566817</td>\n",
       "      <td>0.252456</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>0.432834</td>\n",
       "      <td>0.784063</td>\n",
       "      <td>0.777016</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.066447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.560088</td>\n",
       "      <td>0.496376</td>\n",
       "      <td>0.246389</td>\n",
       "      <td>-0.242109</td>\n",
       "      <td>0.113899</td>\n",
       "      <td>0.317689</td>\n",
       "      <td>0.100926</td>\n",
       "      <td>2.430688</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>0.345890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485228</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>-0.216155</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.875179</td>\n",
       "      <td>0.619286</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.247640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.598593</td>\n",
       "      <td>0.490183</td>\n",
       "      <td>0.240279</td>\n",
       "      <td>-0.402270</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>0.326514</td>\n",
       "      <td>0.106611</td>\n",
       "      <td>2.319456</td>\n",
       "      <td>0.611764</td>\n",
       "      <td>0.322548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517279</td>\n",
       "      <td>0.288856</td>\n",
       "      <td>0.083438</td>\n",
       "      <td>-0.284652</td>\n",
       "      <td>0.389769</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.635630</td>\n",
       "      <td>0.076039</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.186485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>0.489756</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.249895</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.181486</td>\n",
       "      <td>0.032937</td>\n",
       "      <td>5.134281</td>\n",
       "      <td>0.668305</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620978</td>\n",
       "      <td>0.387259</td>\n",
       "      <td>0.149970</td>\n",
       "      <td>-0.483580</td>\n",
       "      <td>0.252763</td>\n",
       "      <td>0.944361</td>\n",
       "      <td>0.459030</td>\n",
       "      <td>0.033215</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.121514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>0.496811</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.249990</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.182557</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>5.099581</td>\n",
       "      <td>0.668425</td>\n",
       "      <td>0.369106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622182</td>\n",
       "      <td>0.387855</td>\n",
       "      <td>0.150432</td>\n",
       "      <td>-0.485234</td>\n",
       "      <td>0.253146</td>\n",
       "      <td>0.944185</td>\n",
       "      <td>0.459416</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.123661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3833 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std       var      skew  canny_mean  canny_std  \\\n",
       "0     0.193280  0.394870  0.155923  1.553524    0.005222   0.072072   \n",
       "1     0.193997  0.395427  0.156362  1.547710    0.012715   0.112043   \n",
       "2     0.234813  0.423882  0.179676  1.251228    0.008669   0.092706   \n",
       "3     0.213588  0.409839  0.167968  1.397679    0.012038   0.109054   \n",
       "4     0.347158  0.476067  0.226639  0.642104    0.030552   0.172102   \n",
       "...        ...       ...       ...       ...         ...        ...   \n",
       "3828  0.794583  0.404006  0.163221 -1.458311    0.173589   0.378756   \n",
       "3829  0.560088  0.496376  0.246389 -0.242109    0.113899   0.317689   \n",
       "3830  0.598593  0.490183  0.240279 -0.402270    0.121333   0.326514   \n",
       "3831  0.489756  0.499895  0.249895  0.040984    0.034100   0.181486   \n",
       "3832  0.496811  0.499990  0.249990  0.012755    0.034518   0.182557   \n",
       "\n",
       "      canny_var  canny_skew    b_mean     b_std  ...    r_mean     r_std  \\\n",
       "0      0.005194   13.730138  0.571313  0.262526  ...  0.651805  0.305004   \n",
       "1      0.012554    8.698198  0.419562  0.185652  ...  0.464023  0.304782   \n",
       "2      0.008594   10.599805  0.690965  0.250440  ...  0.656325  0.323572   \n",
       "3      0.011893    8.949024  0.620038  0.275387  ...  0.597236  0.293364   \n",
       "4      0.029619    5.455466  0.569388  0.316354  ...  0.557730  0.324559   \n",
       "...         ...         ...       ...       ...  ...       ...       ...   \n",
       "3828   0.143456    1.723597  0.656667  0.266853  ...  0.566817  0.252456   \n",
       "3829   0.100926    2.430688  0.578163  0.345890  ...  0.485228  0.304569   \n",
       "3830   0.106611    2.319456  0.611764  0.322548  ...  0.517279  0.288856   \n",
       "3831   0.032937    5.134281  0.668305  0.368840  ...  0.620978  0.387259   \n",
       "3832   0.033327    5.099581  0.668425  0.369106  ...  0.622182  0.387855   \n",
       "\n",
       "         r_var    r_skew  contrast  correlation  dissimilarity    energy  \\\n",
       "0     0.093027 -0.504870  0.013332     0.996856       0.108318  0.110454   \n",
       "1     0.092892 -0.203931  0.013347     0.994628       0.098447  0.037243   \n",
       "2     0.104699 -0.628959  0.036902     0.986431       0.181434  0.036890   \n",
       "3     0.086063  0.096563  0.049787     0.983035       0.194622  0.102886   \n",
       "4     0.105338 -0.141203  0.093375     0.972163       0.298515  0.025722   \n",
       "...        ...       ...       ...          ...            ...       ...   \n",
       "3828  0.063734 -0.247788  0.432834     0.784063       0.777016  0.011110   \n",
       "3829  0.092762 -0.216155  0.390400     0.875179       0.619286  0.151200   \n",
       "3830  0.083438 -0.284652  0.389769     0.858419       0.635630  0.076039   \n",
       "3831  0.149970 -0.483580  0.252763     0.944361       0.459030  0.033215   \n",
       "3832  0.150432 -0.485234  0.253146     0.944185       0.459416  0.032870   \n",
       "\n",
       "           ASM  homogeneity  \n",
       "0     0.012200     0.547112  \n",
       "1     0.001387     0.456429  \n",
       "2     0.001361     0.338114  \n",
       "3     0.010586     0.414035  \n",
       "4     0.000662     0.230964  \n",
       "...        ...          ...  \n",
       "3828  0.000123     0.066447  \n",
       "3829  0.022861     0.247640  \n",
       "3830  0.005782     0.186485  \n",
       "3831  0.001103     0.121514  \n",
       "3832  0.001080     0.123661  \n",
       "\n",
       "[3833 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = images_df.drop(columns = ['mask'])\n",
    "images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Comparing Algorithms</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      " Accuracy: 0.8144861020452566 +/- 0.06850292865490538 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-----------------------Logistic Regression---------------------------------------------\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l2',random_state = 0, max_iter=1000)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"Logistic Regression:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      " Accuracy: 0.7275674499564839 +/- 0.1141218845077428 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------SVM -------------------------------------------------\n",
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"SVM:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      " Accuracy: 0.6498728513925153 +/- 0.09175964747001521 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------Naive Bayes-------------------------------------------\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"Naive Bayes:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      " Accuracy: 0.8635416666666667 +/- 0.05616515424533043\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Random Forest------------------------------------------\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"Random Forest:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      " Accuracy: 0.8139523498694518 +/- 0.07267401084545172\n"
     ]
    }
   ],
   "source": [
    "#----------------------------AdaBoost----------------------------------------------\n",
    "\n",
    "# Fitting AdaBoost Classification to the Training set\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"AdaBoost:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis:\n",
      " Accuracy: 0.8363882996083551 +/- 0.0715015935700874\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Linear Discriminant Analysis--------------------------------------------\n",
    "\n",
    "# Fitting Linear Discriminant Analysis to the Training set\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "classifier = LinearDiscriminantAnalysis()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=images_df , y=target_df , cv = 10)\n",
    "print(\"LinearDiscriminantAnalysis:\\n Accuracy:\", accuracies.mean(), \"+/-\", accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
